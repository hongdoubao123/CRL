{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e452f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "# Resolved an issue where images are too large to be processed by PIL\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import  torchvision\n",
    "from torchvision import datasets, transforms\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\")\n",
    "device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ef9f5cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T11:30:04.192671Z",
     "start_time": "2024-09-04T11:30:04.170186Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_split_data(root: str, tra_rate: float = 0.7, val_rate: float = 0.1, test_rate: float = 0.2):\n",
    "    random.seed(42)  \n",
    "    assert os.path.exists(\n",
    "        root), \"dataset root: {} does not exist.\".format(root)\n",
    "    object_class = [cla for cla in sorted(os.listdir(root)) if os.path.isdir(os.path.join(root, cla))]\n",
    "    num_classes = len(object_class)\n",
    "    class_indices = dict((k, v) for v, k in enumerate(object_class))\n",
    "    json_str = json.dumps(dict((val, key) for key, val in class_indices.items()), indent=4)\n",
    "    with open('class_indices.json', 'w') as json_file:\n",
    "        json_file.write(json_str)\n",
    "\n",
    "    train_images_path = []  \n",
    "    train_images_label = []  \n",
    "    val_images_path = []  \n",
    "    val_images_label = []  \n",
    "    test_images_path = [] \n",
    "    test_images_label = []  \n",
    "\n",
    "    every_class_num = []  \n",
    "    supported = [\".jpg\", \".JPG\", \".png\", \".PNG\"]  \n",
    "    for cla in object_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        images = [os.path.join(root, cla, i) for i in sorted(os.listdir(cla_path))\n",
    "                  if os.path.splitext(i)[-1] in supported]\n",
    "\n",
    "        image_class = class_indices[cla]\n",
    "\n",
    "        total = len(images)\n",
    "        every_class_num.append(total)\n",
    "        random.shuffle(images)\n",
    "        train_images = images[0:int(tra_rate*total)]  \n",
    "        val_images = images[int(tra_rate*total):int((tra_rate+val_rate)*total)] \n",
    "        test_images = images[int((tra_rate+val_rate)*total):]\n",
    "\n",
    "        for img_path in images:\n",
    "            if img_path in train_images:\n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "            if img_path in val_images:\n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "            if img_path in test_images:\n",
    "                test_images_path.append(img_path)\n",
    "                test_images_label.append(image_class)\n",
    "        print(cla, ':', 'count:', total, ' train:', len(train_images),\n",
    "              'val:', len(val_images), 'test:', len(test_images))\n",
    "\n",
    "    print(\n",
    "        f\"There are {len(object_class)} class and {sum(every_class_num)} images were found in the dataset.\")\n",
    "    print(\"{} images for train.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    print(\"{} images for test.\".format(len(test_images_path)))\n",
    "\n",
    "    plot_image = True\n",
    "    save_image = True\n",
    "   \n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label, test_images_path, test_images_label , num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e61aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T11:32:05.515811Z",
     "start_time": "2024-09-04T11:32:05.198285Z"
    }
   },
   "outputs": [],
   "source": [
    "path = r'./Datasets/AiRound/aerial/'\n",
    "train_images_path, train_images_label,val_images_path, val_images_label,test_images_path, test_images_label , num_classes=read_split_data(path,0.7,0.1,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d55dd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T11:32:07.671367Z",
     "start_time": "2024-09-04T11:32:07.653820Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "#     transforms.RandomResizedCrop(224,scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.6959, 0.6537, 0.6371), (0.3113, 0.3192, 0.3214)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "#     transforms.RandomResizedCrop(224,scale=(0.7,1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.6959, 0.6537, 0.6371), (0.3113, 0.3192, 0.3214)),\n",
    "\n",
    "])\n",
    "class Add(Dataset):\n",
    "    def __init__(self, Dataset,Labels,transform = None,target_transform = None):\n",
    "        self.List = Dataset\n",
    "        self.Labels = Labels\n",
    "        self.length = len(self.List)\n",
    "        if transform is None:\n",
    "            self.transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.List[index]).convert(\"RGB\")\n",
    "        label = self.Labels[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "#         image = np.transpose(img,(2,0,1))\n",
    "        return img,label,index\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def getData(self):\n",
    "        return self.List, self.Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692f613e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T11:32:11.771544Z",
     "start_time": "2024-09-04T11:32:11.762081Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = Add(train_images_path,train_images_label,transform = transform_train)\n",
    "val_images = Add(val_images_path,val_images_label,transform = transform_train)\n",
    "test_images = Add(test_images_path,test_images_label,transform = transform_test)\n",
    "train_loader = DataLoader(dataset=train_images, batch_size=16, num_workers=8, pin_memory=True, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(dataset=val_images, batch_size=8, num_workers=8, pin_memory=True, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(dataset=test_images, batch_size=8, num_workers=8, pin_memory=True, shuffle=False, drop_last=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
