{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f425f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T01:05:56.727479Z",
     "start_time": "2024-09-03T01:05:54.391633Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "%run dataloader.ipynb\n",
    "# %run dataloader_ori.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e458a16e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T01:05:58.629920Z",
     "start_time": "2024-09-03T01:05:58.621608Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import time\n",
    "import datetime\n",
    "import  torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes =9 \n",
    "val_nums = np.zeros(num_classes, dtype=int)\n",
    "for item in clean_val_dataset_label:\n",
    "    val_nums[item] += 1\n",
    "# print(\"val categroy mean\", np.mean(val_nums, dtype=int), \"category\", val_nums, \"precent\", val_nums / np.mean(val_nums))\n",
    "train_nums = np.zeros(num_classes, dtype=int)\n",
    "for item in train_dataset_label:\n",
    "    train_nums[item] += 1\n",
    "# print(\"train categroy mean\", np.mean(train_nums, dtype=int), \"category\", train_nums, \"precent\", np.mean(train_nums) / train_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe875158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:16:46.410041Z",
     "start_time": "2024-05-15T10:16:44.217055Z"
    }
   },
   "outputs": [],
   "source": [
    "class_weights = torch.FloatTensor(np.mean(train_nums) / train_nums * val_nums / np.mean(val_nums)).to(device)\n",
    "model = torchvision.models.resnet50(pretrained = True)\n",
    "model.fc = nn.Linear(2048,num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e73f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:16:46.478504Z",
     "start_time": "2024-05-15T10:16:46.472115Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[40], gamma=0.1)\n",
    "ceriation = nn.CrossEntropyLoss(weight=class_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b90d7ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:16:46.649238Z",
     "start_time": "2024-05-15T10:16:46.539119Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {avg' + self.fmt + '}'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "    \n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "    \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "def getTime():\n",
    "    time_stamp = datetime.datetime.now()\n",
    "    return time_stamp.strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed4d2892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:16:46.733165Z",
     "start_time": "2024-05-15T10:16:46.715508Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_iter, ceriation, train_optimizer, num_prints=1):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':6.3f')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_iter),\n",
    "        [batch_time, data_time, losses, top1], prefix=\"Train \")\n",
    "\n",
    "    end = time.time()\n",
    "    num_iter = int((len(train_iter)-1) / num_prints)\n",
    "    for batch_idx in range(num_iter):\n",
    "        try:\n",
    "            images, labels,_ = train_iter.next()\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "        data_time.update(time.time() - end)\n",
    "        train_optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = ceriation(logits, labels)\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        train_optimizer.step()\n",
    "\n",
    "        acc1, acc5 = accuracy(logits, labels, topk=(1, 5))\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "        top1.update(acc1[0], images[0].size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    progress.display(batch_idx)\n",
    "    return top1.avg, losses.avg\n",
    "\n",
    "\n",
    "def evaluate(model, eva_loader, ceriation, prefix, ignore=-1):\n",
    "    losses = AverageMeter('Loss', ':3.2f')\n",
    "    top1 = AverageMeter('Acc@1', ':3.2f')\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels,_) in enumerate(eva_loader):\n",
    "            images = Variable(images).cuda()\n",
    "            labels = Variable(labels).cuda()\n",
    "\n",
    "            logist = model(images)\n",
    "\n",
    "            loss = ceriation(logist, labels)\n",
    "            acc1, acc5 = accuracy(logist, labels, topk=(1, 5))\n",
    "\n",
    "            losses.update(loss.item(), images[0].size(0))\n",
    "            top1.update(acc1[0], images[0].size(0))\n",
    "\n",
    "    if prefix != \"\":\n",
    "        print(getTime(), prefix, round(top1.avg.item(), 2))\n",
    "\n",
    "    return losses.avg, top1.avg.to(\"cpu\", torch.float).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdd15c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:21:34.321254Z",
     "start_time": "2024-05-15T10:16:46.795736Z"
    }
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "epoch_a = 50\n",
    "for i in range(epoch_a):\n",
    "    train_iter = iter(train_loader)\n",
    "    print(\"Start training epoch:{}\".format(i))\n",
    "    train(model, train_iter, ceriation, optimizer,1)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, ceriation, \"Epoch \" + str(i) + \", Val Acc:\")\n",
    "    _, test_acc = evaluate(model, test_loader, ceriation, \"Epoch_test \"+ \", Test Acc1:\")\n",
    "    if test_acc>best:\n",
    "        best = test_acc\n",
    "        torch.save(model,'save_init_air_model')\n",
    "    print(getTime(), \"Init Best Test Acc1:\", best)\n",
    "    scheduler.step()\n",
    "# The warm-up has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "601c0453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:21:34.650874Z",
     "start_time": "2024-05-15T10:21:34.590717Z"
    }
   },
   "outputs": [],
   "source": [
    "class Add2(Dataset):\n",
    "    def __init__(self, Dataset,Labels,transform = None,target_transform = None):\n",
    "        self.List = Dataset\n",
    "        self.Labels = Labels\n",
    "        self.length = len(self.List)\n",
    "        if transform is None:\n",
    "            self.transform = transforms.ToTensor()\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        print(\"NewDataset length:\", self.length)\n",
    "        self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.List[index]).convert(\"RGB\")\n",
    "        label = self.Labels[index]\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img)\n",
    "            img2 = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        return img1,img2,label\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a24093",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:21:35.036690Z",
     "start_time": "2024-05-15T10:21:34.827409Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_dataset = Add2(train_dataset_path, train_dataset_label , transform=transform_train)\n",
    "predict_loader = DataLoader(dataset=predict_dataset, batch_size=16, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c7a1b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:21:35.109919Z",
     "start_time": "2024-05-15T10:21:35.103026Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_softmax(predict_loader, model):\n",
    "    model.eval()\n",
    "    softmax_outs = []\n",
    "    with torch.no_grad():\n",
    "        for images1, images2,_ in predict_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                images1 = Variable(images1).cuda()\n",
    "                images2 = Variable(images2).cuda()\n",
    "                logits1 = model(images1)\n",
    "                logits2 = model(images2)\n",
    "                outputs = (F.softmax(logits1, dim=1) + F.softmax(logits2, dim=1)) / 2\n",
    "                softmax_outs.append(outputs)\n",
    "\n",
    "    return torch.cat(softmax_outs, dim=0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2faa7df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T11:27:36.920843Z",
     "start_time": "2024-05-15T11:27:36.873530Z"
    }
   },
   "outputs": [],
   "source": [
    "def splite_confident(outs,noisy_targets,noisy_imagepath , Flag):\n",
    "    probs, preds = torch.max(outs.data, 1)  # return the value and the index\n",
    "    pred1 = preds.numpy() \n",
    "    probs1 = probs.numpy()\n",
    "    confident_indexs = []\n",
    "    unconfident_indexs = []\n",
    "    for i in range(0, len(noisy_targets)):\n",
    "        if preds[i] == noisy_targets[i] and probs1[i]>=0.5: \n",
    "            confident_indexs.append(i)\n",
    "        else:\n",
    "            unconfident_indexs.append(i)\n",
    "\n",
    "    print(getTime(), \"total and confident and unconfident num:\",len(noisy_imagepath),len(confident_indexs), len(unconfident_indexs))\n",
    "    new_confident1 = []\n",
    "    new_unconfident1 = []\n",
    "    new_confident_label1 = []\n",
    "    new_unconfident_label1 = []\n",
    "    for t in range(0,len(noisy_imagepath)):\n",
    "        if t in confident_indexs:\n",
    "            new_confident1.append(noisy_imagepath[t])\n",
    "            new_confident_label1.append(pred1[t])\n",
    "        else:\n",
    "            new_unconfident1.append(noisy_imagepath[t])\n",
    "            new_unconfident_label1.append(pred1[t])\n",
    "    new_train_image1 = Add(new_confident1,new_confident_label1,transform=transform_train)\n",
    "    new_trainloader1 = DataLoader(dataset=new_train_image1, batch_size=8, num_workers=8, pin_memory=True, shuffle=True, drop_last=True)\n",
    "    return new_trainloader1,new_confident1, new_confident_label1, new_unconfident1, new_unconfident_label1, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a33e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T01:26:14.469135Z",
     "start_time": "2024-03-14T01:23:24.739235Z"
    }
   },
   "outputs": [],
   "source": [
    "soft_outs = predict_softmax(predict_loader, model)\n",
    "new_trainloader,new_confident, new_confident_label, new_unconfident, new_unconfident_label = splite_confident(soft_outs,train_dataset_label,train_dataset_path)\n",
    "clip = len(new_unconfident)/len(train_dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd9282fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T02:10:40.528043Z",
     "start_time": "2024-03-14T02:10:40.489910Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ori(model,train_iter,criterion,optimizer,clip):\n",
    "    clip = 1-clip\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':6.3f')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_iter),\n",
    "        [batch_time, data_time, losses, top1], prefix=\"Train \")\n",
    "              \n",
    "    end = time.time()\n",
    "    num_iter = int((len(train_iter) - 1))\n",
    "    for batch_idx in range(num_iter):\n",
    "        try:\n",
    "            images, labels,_ = train_iter.next()\n",
    "            data = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        model.train()\n",
    "        data_time.update(time.time() - end)\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.requires_grad_(True)\n",
    "        loss.backward()\n",
    "        \n",
    "# update crucial parameters        \n",
    "        to_concat_g = []\n",
    "        to_concat_v = []\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.dim() in [2, 4]:\n",
    "                to_concat_g.append(param.grad.data.view(-1))\n",
    "                to_concat_v.append(param.data.view(-1))\n",
    "        #             print(to_concat_g)\n",
    "        #             print(to_concat_v) \n",
    "        all_g = torch.cat(to_concat_g)\n",
    "        all_v = torch.cat(to_concat_v)\n",
    "        metric = torch.abs(all_g * all_v)\n",
    "        num_params = all_v.size(0)\n",
    "#             print(num_params)\n",
    "        nonzero_ratio = clip\n",
    "        nz = int(nonzero_ratio * num_params)\n",
    "        top_values, _ = torch.topk(metric, nz)\n",
    "#             print(top_values)\n",
    "        thresh = top_values[-1]\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.dim() in [2, 4]:\n",
    "                mask1 = (torch.abs(param.data * param.grad.data) >= thresh).type(torch.cuda.FloatTensor)\n",
    "                mask2 = (torch.abs(param.data * param.grad.data) < thresh).type(torch.cuda.FloatTensor)\n",
    "                mask1 = mask1 * clip\n",
    "                mask2 = mask2 * (1-clip)\n",
    "                mask = mask1+mask2\n",
    "                param.grad.data = mask * param.grad.data\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        acc1, acc5 = accuracy(pred, labels, topk=(1, 5))\n",
    "        losses.update(loss.item(), data[0].size(0))\n",
    "        top1.update(acc1[0], data[0].size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "    progress.display(batch_idx)\n",
    "    return top1.avg, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712d7b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-14T02:21:19.814289Z",
     "start_time": "2024-03-14T02:10:43.246155Z"
    }
   },
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "epoch_b = 150\n",
    "cll = []\n",
    "for j in range(epoch_b):\n",
    "    if j%20==0:\n",
    "        soft_outs = predict_softmax(predict_loader, model)\n",
    "        new_trainloader,new_confident, new_confident_label, new_unconfident, new_unconfident_label = splite_confident(soft_outs,train_dataset_label,train_dataset_path)\n",
    "        new_clip  = clip*len(new_unconfident)/len(train_dataset_label)\n",
    "        if new_clip<clip:\n",
    "            clip = new_clip\n",
    "    train_iter = iter(new_trainloader)\n",
    "    print(\"Start training epoch:{}\".format(j))\n",
    "    train_ori(model,train_iter,ceriation,optimizer,clip)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, ceriation, \"Epoch \" + str(j) + \", Val Acc:\")\n",
    "    scheduler.step()\n",
    "    _, test_acc = evaluate(model, test_loader, ceriation, \"Epoch_test \"+ \", Test Acc1:\")\n",
    "    if test_acc>=best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model,'our_air_model')\n",
    "    print(getTime(), \"Model Best Test Acc1:\", best_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
